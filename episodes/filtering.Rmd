---
title: 'Filtering data'
teaching: 15
exercises: 10
---

:::::::::::::::::::::::::::::::::::::: questions 

- How do you filter invalid data?
- How do you chain commands using the pipe `%>%`? 
- How can I select only some columns of my data?

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Explain how to filter rows using `filter()`
- Demonstrate how to select columns using `select()`
- Explain how to use the pipe `%>%` to facilitate clean code

::::::::::::::::::::::::::::::::::::::::::::::::

## Filtering
In the earlier episodes, we have already seen some impossible values in `age` and `testelapse`. In our analyses, we probably want to exclude those values, or at the very least investigate what is wrong. In order to do that, we need to *filter* our data - to make sure it only has those observations that we actually want. The `dplyr` package provides a useful function for this: `filter()`.

Let's start by again loading in our data, and also loading the package `dplyr`.

```{r}
library(dplyr)

dass_data <- read.csv("data/kaggle_dass/data.csv")
```

The `filter` function works with two key inputs, the data and the arguments that you want to filter by. The data is always the first argument in the filter function. The following arguments are the filter conditions. 
For example, in order to only include people that are 20 years old, we can run the following code:

```{r}
twenty_year_olds <- filter(dass_data, age == 20)
# Lets make sure this worked
table(twenty_year_olds$age)

# range(twenty_year_olds$age) # OR THIS
# unique(twenty_year_olds$age) # OR THIS
# OR other things that come to mind can check this
```
Now, in order to only include participants aged between 0 and 100, which seems like a reasonable range, we can condition on `age >= 0 & age <= 100`.

```{r}
valid_age_dass <- filter(dass_data, age >= 0 & age <= 100)
```

Let's check if this worked using a histogram.
```{r}
hist(valid_age_dass$age, breaks = 50)
```

Looks good! Now it is always a good idea to inspect the values you removed from the data, in order to make sure that you did not remove something you intended to keep, and to learn something about the data you removed.

Let's first check how many rows of data we actually removed:
```{r}
n_rows_original <- nrow(dass_data)

n_rows_valid_age <- nrow(valid_age_dass)

n_rows_removed <- n_rows_original - n_rows_valid_age

n_rows_removed
```

This seems okay! Only 7 removed cases out of almost 40000 entries is negligible. Nonentheless, let's investigate this further.

```{r}
impossible_age_data <- filter(dass_data, age < 0 | age > 100)
```

Now we have a dataset that contains only the few cases with invalid ages. We can just look at the ages first:

```{r}
impossible_age_data$age
```

Now, let's try investigating the a little deeper. Do the people with invalid entries in age have valid entries in the other columns? Try to figure this out by visually inspecting the data. Where are they from? Do the responses to other questions seem odd?

This is possible, but somewhat hard to do for data with 170 columns. Looking through all of them might make you a bit tired after the third investigation of invalid data. What we really need is to look at only a few columns that interest us. 

## Selecting columns

This is where the function `select()` comes in. It enables us to only retain some columns from a dataset for further analysis. You just give it the data as the first argument and then list all of the columns you want to keep.

```{r}
inspection_data_impossible_age <- select(
    impossible_age_data,
    age, country, engnat, testelapse
  )

inspection_data_impossible_age
```

Here, we can see that our original data is reduced to the four columns we specified above `age, country, engnat, testelapse`. Do any of them look strange? What happened in the age column?

To me, none of the other entries seem strange, the time it took them to complete the survey is plausible, they don't show a clear trend of being from the same country. It seems that some people mistook the age question and entered their year of birth instead. Later on, we can try to fix this.

But before we do that, there are some more things about `select()` that we can learn. It is one of the most useful functions in my daily life, as it allows me to keep only those columns that I am actually interested in. And it has many more features than just listing the columns!

For example, note that the last few columns of the data are all the demographic information. This is starting with `education` and ending with `major`.

To select everything from `education` to `major`:
```{r}
# colnames() gives us the names of the columns only
colnames(select(valid_age_dass, education:major))
```

We can also select all character columns using `where()`:
```{r}
colnames(select(valid_age_dass, where(is.character)))
```
Or we can select all columns that start with the letter "Q":

```{r}
colnames(select(valid_age_dass, starts_with("Q")))
```
There are a number of helper functions you can use within `select()`:

- `starts_with("abc")`: matches names that begin with “abc”.
- `ends_with("xyz")`: matches names that end with “xyz”.
- `contains("ijk")`: matches names that contain “ijk”.
- `num_range("x", 1:3)`: matches `x1`, `x2` and `x3`.

You can also remove columns using select by simply negating the argument using `!`:
```{r}
colnames(select(valid_age_dass, !starts_with("Q")))
```

Now we will only get those columns that *don't* start with "Q".

::: callout
## Selecting a column twice
You can also use select to reorder the columns in your dataset. For example, notice that the following two bits of code return differently order data:

```{r}
# head() gives us the first 10 values only
head(select(valid_age_dass, age, country, testelapse), 10) 
```

```{r}
head(select(valid_age_dass, testelapse, age, country), 10)
```

Using the function `everything()`, you can select all columns. 

What happens, when you select a column twice? Try running the following examples, what do you notice about the position of columns?

```{r, eval = FALSE}
select(valid_age_dass, age, country, age)

select(valid_age_dass, age, country, everything())
```
:::


## Using the pipe `%>%` 
Let's retrace some of the steps that we took. We had the original data `dass_data` and then filtered out those rows with invalid entries in age. Then, we tried selecting only a couple of columns in order to make the data more manageable. In code:

```{r, eval = FALSE}
impossible_age_data <- filter(dass_data, age < 0 | age > 100)

inspection_data_impossible_age <- select(impossible_age_data, age, country, engnat, testelapse)
```

Notice how the first argument for both the `filter()` and the `select()` function is always the data. This is also true for the `ggplot()` function. And it's no coincidence! In R, there exists a special symbol, called the pipe `%>%`, that has the following property: It takes the output of the previous function and uses it as the first input in the following function.

This can make our example considerably easier to type:
```{r}
dass_data %>% 
  filter(age < 0 | age > 100) %>% 
  select(age, country, engnat, testelapse)
```

Notice how the pipe is always written at the end of a line. This makes it easier to understand and to read. As we go to the next line, whatever is outputted is used as input in the following line. So the original data `dass_data` is used as the first input in the filter function, and the filtered data is used as the first input in the `select` function.

To use the pipe, you can either type it out yourself or use the Keyboard-Shortcut `Ctrl + Shift + M`.

## Plotting using the pipe

We have seen that the pipe `%>%` allows us to chain multiple functions together, making our code cleaner and easier to read. This can be particularly useful when working with `ggplot2`, where we often build plots step by step. Since `ggplot()` takes the data as its first argument, we can use the pipe to make our code more readable.

For example, let’s say we want to create a histogram of valid ages in our dataset. Instead of writing:

```{r}
library(ggplot2)

ggplot(valid_age_dass, aes(x = age)) +
  geom_histogram(bins = 50)
```

We can write:

```{r}
valid_age_dass %>%
  ggplot(aes(x = age)) +
  geom_histogram(bins = 50)
```

This makes it clear that `valid_age_dass` is the dataset being used, and it improves readability.

::: callout
## Using the pipe for the second argument
By default, the pipe places the output of the previous code as the first argument in the following function. In most cases, this is exactly what we want to have. If you want to be more explicit about where the pipe should place the output, you can do this by placing a `.` as the placeholder for piped-data.

```{r}
n_bins <- 30

n_bins %>%
  hist(valid_age_dass$age, .)
```
:::

## Numbered vs. Named Arguments

The pipe is made possible because most functions in the packages included in `tidyverse`, like `dplyr` and `ggplot` have the data as their first argument. This makes it simple to pipe-through results from one function to the next, without having to explicitly type `function(data = something)` every time. In principle, almost all functions have a natural order in which they expect arguments to occur. For example: `ggplot()` expects data as the first argument and information about the mapping as the second argument. This is why we always typed:


```{r}
ggplot(
  data = valid_age_dass,
  mapping = aes(x = age)
)+
  geom_density()
```

Notice that if we don't specify the argument names, we still receive the same results. The function just uses the inputs you give it to match the arguments in the order in which they occur.

```{r}
ggplot(
  valid_age_dass, # Now it just automatically thinks this is data = 
  aes(x = age) # and this is mapping = 
)+
  geom_density()
```

This is what makes this possible:
```{r}
valid_age_dass |>
  ggplot(aes(x = age)) +
  geom_density()
```

However, if we try to supply an argument in a place where it doesn't belong, we get an error:
```{r}
n_bins = 50 
valid_age_dass |>
  ggplot(aes(x = age)) +
  geom_histogram(n_bins)  # This will cause an error!
```

`geom_histogram` does not expect the number of bins to be the first argument, but rather the mapping! Therefore, we need to declare this properly:
```{r}
valid_age_dass |>
  ggplot(aes(x = age)) +
  geom_histogram(bins = n_bins)  # This will cause an error!
```
To learn about the order of arguments of a function, use `?function` and inspect the help file.

## Common Problems

### Using one pipe too little

A common mistake is forgetting to use a pipe between arguments of a chain. For example:

```{r, eval = FALSE, error = TRUE}
valid_age_dass %>% 
  filter(age > 18)
  select(age, country)
```

Here, `select()` is not part of the pipeline because the pipe is missing after `filter(age > 18)`. This can lead to unexpected errors or incorrect results. The correct way to write this is:

```{r, eval = FALSE}
valid_age_dass %>% 
  filter(age > 18) %>% 
  select(age, country)
```

### Using one pipe too much

Another common problem is using one pipe too many without having a function following it.
```{r, error = TRUE}
valid_age_dass %>% 
  filter(age > 18) %>% 
  select(age, country) %>% 
```
This can cause some really strange errors that never say anything about the pipe being superfluous. Make sure that all your pipe "lead somewhere".

### Using a pipe instead of `+` for `ggplot()`
A source of confusion stems from the difference between the pipe `%>%` and `ggplot2`'s `+`. They both serve very similar purposes, namely adding together a chain of functions. However, make sure you use `%>%` for everything *except* ggplot-functions. Here, you will also receive an error that is a little more informative:

```{r}
valid_age_dass %>% 
  ggplot(aes(x = age)) %>% 
  geom_density()
```

### Using `=` Instead of `==` in `filter()`

Another common error is using `=` instead of `==` when filtering data. For example:

```{r}
valid_age_dass %>% 
  filter(country = "US") %>%  # Incorrect!
  head()
```

This will result in an error because `=` is used for assigning values, while `==` is used for comparisons. The correct syntax is:

```{r}
valid_age_dass %>% 
  filter(country == "US") %>% 
  head()
```

## Challenges

::: challenge
## Challenge 1
Filter the complete `dass_data`. Create one dataset containing only entries with people from the United States and one dataset containing only entries from Great Britain. Compare the number of entries in each dataset. What percentage of the total submissions came from these two countries?

What is the average age of participants from the two countries?

:::

::: challenge
## Challenge 2
Create a filtered dataset based on the following conditions:

- Length of test is smaller than 30 minutes
- English is the native language
- There is an entry in the field `major`

:::

::: challenge
## Challenge 3

What arguments does the `cut()` function take? Make a list of the arguments and the order in which they have to be provided to the function.
:::

::: challenge
## Challenge 4

In a singly chain of functions, create a dataset is filtered based on the columns above and contains only the following variables:

- all demographic information
- all the answers to the DASS (and only the answers, not the position or timing)
:::

::: challenge
## Challenge 5

Save that dataset to a file `english_university_dass_data.csv` in your `processed_data` folder. You may need to use Google to find a function that can do this.

:::

::::::::::::::::::::::::::::::::::::: keypoints 

- Use the pipe operator `%>%` to link multiple functions together
- Use `filter()` to filter rows based on certain conditions
- Use `select()` to keep only those rows that interest you

::::::::::::::::::::::::::::::::::::::::::::::::

